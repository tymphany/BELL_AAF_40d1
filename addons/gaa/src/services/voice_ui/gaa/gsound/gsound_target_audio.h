// Copyright 2018 Google LLC.
#ifndef GSOUND_TARGET_AUDIO_H
#define GSOUND_TARGET_AUDIO_H

#ifdef __cplusplus
extern "C" {
#endif

/**
 * This header file was generated by Google GSound Services,
 * it should not be altered in any way. Please treat this as
 * a read-only file.
 *
 * Each function listed below must
 * be implemented for each specific
 * platform / SDK
 *
 */
#include "gsound.h"

/**
 * List of audio clips required by GSound.  These values will be passed to the
 * Target using the Audio Out APIs below to be played on headset.
 *
 * Note: Any offline VUI error prompts provided by Google are intended
 * as reference only. Google expects the partner to generate using their own
 * voice and ensure proper translation for each supported locale.
 */
typedef enum {
  /**
   * Clip to be played when mic is opened by a GA_VOICE_PREPARE Action
   */
  GSOUND_AUDIO_OUT_CLIP_PREPARE_MIC_OPEN,

  /**
   * Clip to be played when a GA_VOICE_PTT Action is received after
   * GA_VOICE_PREPARE
   */
  GSOUND_AUDIO_OUT_CLIP_PTT_QUERY,

  /**
   * Clip to be played if GA_VOICE_PTT and GA_VOICE_PREPARE Actions are received
   * in the same call.
   */
  GSOUND_AUDIO_OUT_CLIP_PTT_MIC_OPEN,

  /**
   * Clip to be played when Assistant on the phone requests a mic open clip.
   * Assistant on the phone may request this for hotword or follow on queries,
   * but this behavior is not gauranteed and may change based on user settings
   * or UX studies.
   */
  GSOUND_AUDIO_OUT_CLIP_REMOTE_MIC_OPEN,

  /**
   * Clip to be played when a GA_VOICE_DONE Action is received in a PTT query
   * state. Not played when exiting PREPARE state.
   */
  GSOUND_AUDIO_OUT_CLIP_PTT_MIC_CLOSE,

  /**
   * Clip to be played when Assistant on the phone requests a mic close clip
   * after a CTT, hotword or remote query.
   */
  GSOUND_AUDIO_OUT_CLIP_REMOTE_MIC_CLOSE,

  /**
   * Clip to be played when any gesture that invokes the Google Assistant is
   * performed, but there is no GA connection to the phone.
   */
  GSOUND_AUDIO_OUT_CLIP_GSOUND_NC,

  /**
   * Clip to be played when a GA_FETCH Action is received. Note: this is not
   * played on GA_FETCH_PREPARE
   */
  GSOUND_AUDIO_OUT_CLIP_FETCH,

  /*
   * Clip to be played when an ongoing voice query is interrupted (e.g. on
   * forced role change).
   */
  GSOUND_AUDIO_OUT_CLIP_QUERY_INTERRUPTED,

  /*
   * Clip to be played when a valid VOICE_PTT Action is received, but cannot be
   * fulfilled (e.g. we are in the middle of a role change). Also played if
   * VOICE_PREPARE was ignored due to role change or HFP
   */
  GSOUND_AUDIO_OUT_CLIP_PTT_REJECTED,

} GSoundTargetAudioOutClip;

/**
 * The following specifies the required settings for the
 * SBC encoder. Note the only setting which is not hard-coded
 * is the bitpool which is provided to the Target at runtime using
 * the data structure below.
 *
 * The SBC algorithm used is defined in the A2DP specification.
 * Note, GSound does NOT use mSBC.
 *
 * SBC Encoder Settings:
 *    - Sample frequency  - 16000 Hz
 *    - Bits/Sample       - 16 bits
 *    - Channel mode      - Mono
 *    - Subband           - 8
 *    - Block Length      - 16
 *    - Bitpool           - 12 to 24
 *    - Allocation method - SBC_ALLOC_METHOD_LOUDNESS
 */
typedef struct {
  /**
   * bitpool setting for SBC encoded provided by GSound
   * to Target at runtime.
   *
   * This value can range from 12 to 24 depending on
   * the bandwidth available in the current connection.
   */
  uint32_t sbc_bitpool;

  /**
   * When true the side tone should be enabled at the same time the microphone
   * is opened.
   * Side tone should be disabled when the mic is closed by
   * GSoundTargetAudioInClose.
   */
  bool enable_sidetone;

  /**
   * When true the gsound_target_on_audio_in_ex must be called and raw samples
   * are required. This is used for 1st stage hotword evaluation. If
   * raw_samples_required is ever true on this platform then
   */
  bool raw_samples_required;

  /**
   * When true include sbc headers with encoded audio.
   *
   * By default always strip the 4 byte SBC headers before frames are sent to
   * GSound. If this value is true include the encoded_frame_len parameter to
   * gsound_target_on_audio_in_ex must include the 4 byte header.
   */
  bool include_sbc_headers;
} GSoundTargetAudioInSettings;

/**
 * List of reasons that gsound may call GSoundTargetAudioPrepareForStreaming.
 */
typedef enum {
  GSOUND_AUDIO_STREAM_VOICE_QUERY = 0,
  GSOUND_AUDIO_STREAM_HOTWORD_DETECTION,
} GSoundTargetAudioStreamingReason;

/**
 * List of reasons that target may call the audio_in_stream_interrupted
 * callback.
 */
typedef enum {

  /**
   * HFP call has interrupted the audio in stream
   */
  GSOUND_AUDIO_IN_STREAM_INTERRUPTED_REASON_HFP = 0,

  /**
   * The VAD has indicated that the mic should be temporarily disabled, and
   * some audio was not sent to GSound.
   */
  GSOUND_AUDIO_IN_STREAM_INTERRUPTED_REASON_VAD,

} GSoundTargetAudioInStreamIntReason;

/**
 * See GSoundTargetAudioPrepareForStreaming.
 */
typedef struct {
  GSoundTransport connected_transport;
  GSoundBTAddr connected_address;
  GSoundTargetAudioStreamingReason reason;
} GSoundTargetAudioStreamingSettings;

typedef struct {
  /**
   * Callback which should be executed by Target every time audio input data is
   * available.
   *
   * May only be used when "raw_samples_required" in GSoundTargetAudioInSettings
   * passed to GSoundTargetAudioInOpen is false.
   *
   * See gsound_target_on_audio_in_ex for details on the encoded data format.
   */
  GSoundStatus (*gsound_target_on_audio_in)(const uint8_t *encoded_data,
                                            uint32_t encoded_payload_length,
                                            uint32_t encoded_frame_len);

  /**
   * Callback which should be executed by Target every time audio input data is
   * available.
   *
   * If raw_samples_required is false in the GSoundTargetAudioInSettings passed
   * to GSoundTargetAudioInOpen, then the raw_data is optional and may be NULL.
   *
   * In all cases the encoded_data, encoded_payload_length and
   * encoded_frame_length are required.
   *
   * For SBC, GSound requires that the frame header is removed from
   * each audio frame.
   *
   * Target should either a) encode one frame at a time, or b) provide multiple
   * frames - in both cases all of the frame headers must be removed
   *
   * a) _________________________________
   *    | Scaling Factor | Audio Samples |
   *    |________________|_______________|
   *
   * b) __________________________________________________________________
   *    | Scaling Factor | Audio Samples | Scaling Factor | Audio Samples | ...
   *    |________________|_______________|________________|_______________|
   *
   * Data passed to this function will be copied, caller does not have
   * to retain after this callback returns.
   *
   * All calls to this function must be serialized (i.e. from a single
   * thread/task) in order to preserve audio frame order.
   *
   * Note: In case of a TWS system - target layer must still
   * execute this callback and provide SBC encoded audio input to the master
   * whether the microphone is on the Master or Slave device.
   *
   * param[in]: raw_data:               Pointer to raw 16 bit PCM audio samples.
   * param[in]: raw_data_length:        Number of elements in raw_data.
   * param[in]: encoded_data:           Pointer to SBC encoded data
   * param[in]: encoded_payload_length: Number of bytes in encoded_data
   * param[in]: encoded_frame_len:      Size of each frame in bytes (without the
   *                                    header)
   *
   * Returns GSOUND_STATUS_OK unless the encoded_frame_len does not match
   * expectations based on the sbc_bitpool configured in
   * GSoundTargetAudioInSettings .
   */
  GSoundStatus (*gsound_target_on_audio_in_ex)(const uint16_t *raw_data,
                                               uint32_t raw_data_length,
                                               const uint8_t *encoded_data,
                                               uint32_t encoded_payload_length,
                                               uint32_t encoded_frame_len);

  /**
   * It is acceptable for the Target to diverge the audio input stream from
   * GSound to an alternate consumer as required by the application. For
   * example, if an HFP phone call starts after GSound has opened the
   * microphone (via GSoundTargetAudioInOpen), Target can diverge the audio
   * stream to the HFP controller.
   *
   * The Target must re-route the audio input stream back to GSound once the
   * interruption has completed. In such cases, Target MUST call this API when
   * the audio input stream is ready to be routed back to GSound.
   *
   * For example:
   *
   * If an HFP phone call starts after GSound has opened the microphone, the
   * Target must call this API after the phone call ends.
   * If SoC contains a VAD (voice activity detector), Target must call this
   * API every time VAD has detected activity and is ready to send audio input
   * data to GSound.
   *
   * Note: This API must be called BEFORE `gsound_target_on_audio_in` or
   * `gsound_target_on_audio_in_ex` are called again.
   *
   * Note: Target is required to maintain the GSoundTargetAudioInSettings
   * provided by the more recent call to GSoundTargetAudioInOpen during an
   * interruption. Target must use those settings when resuming the audio
   * stream back to GSound.
   *
   * Note: Target must not route audio back to GSound if the audio input stream
   * was closed (via GSoundTargetAudioInClose) during an interruption
   *
   * This API must be called from the same thread/task which calls
   * gsound_target_on_audio_in/gsound_target_on_audio_in_ex.
   *
   * param reason[in]:   indicates why this API was called (HFP or VAD)
   *
   * Returns GSOUND_STATUS_OK.
   */
  GSoundStatus (*audio_in_stream_interrupted)(
      GSoundTargetAudioInStreamIntReason reason);

} GSoundAudioInterface;

/**
 * Play audio clip provided. Target should
 * have a WAV, MP3, etc. file embedded in the application.
 * Use the clip parameter to determine which file to play.
 *
 * Note: This function must be non-blocking. It will be called
 * from a thread context.
 *
 * Note: In case of a TWS system - target layer must be capable of playing audio
 * and voice prompts on both master and slave when prompted from this API
 * on master.
 *
 * param[in]: clip: Audio clip to play back to user. Each clip should refer to a
 *                  unique wav file.
 */
GSoundStatus GSoundTargetAudioOutStart(GSoundTargetAudioOutClip clip);

/**
 * Initialize Audio Playback subsystem
 */
GSoundStatus GSoundTargetAudioOutInit(void);

/**
 * Close the Microphone audio input path and side-tone. After this call,
 * GSound should no longer receive audio frames.
 *
 * Note, If Audio In is already closed when this function is called, Target
 * should do nothing and return GSOUND_STATUS_SUCCESS.
 */
GSoundStatus GSoundTargetAudioInClose(void);

/**
 * Open the Microphone audio input port and start streaming
 * SBC encoded audio frames to GSound using the appropriate
 * callback Interface above. If the `sidetone_required` field is true, target
 * must also provide a side-tone to speakers so user can hear their voice while
 * speaking.
 *
 * Note that sidetone may also be enabled or disabled from the
 * GSoundTargetSetSidetone API.
 *
 * GSoundTargetAudioInOpen may be called several times in succession without
 * any calls to GSoundTargetAudioInClose. In these cases it is up to the target
 * to apply any updated parameters from the audio_in_settings argument.
 *
 * param[in]: audio_in_settings SBC encoder settings. Refer to
 *                              GSoundTargetAudioInSettings definition for
 *                              more detail.
 *
 */
GSoundStatus GSoundTargetAudioInOpen(
    const GSoundTargetAudioInSettings *audio_in_settings);

/**
 * API to enable/disable sidetone when the microphone is already open.
 *
 * Target should not interrupt or alter the audio input stream when enabling or
 * disabling sidetone through this API.
 *
 * Note that this API will only be called when the microphone has been opened by
 * GSoundTargetAudioInOpen.
 *
 * Also note that GSoundTargetAudioInOpen may also enable sidetone without
 * calling this API.
 *
 * param[in]: sidetone_enabled   true   enable sidetone. If sidetone is already
 *                                      enabled then ignore.
 *
 *                               false  disable sidetone. If sidetone is already
 *                                      disabled then ignore.
 */
GSoundStatus GSoundTargetSetSidetone(bool sidetone_enabled);

/**
 * The target should perform any preparation necessary to enable high-throughput
 * audio streaming over BT/BLE. This includes any configurations required to BT,
 * BLE, MCU clock rate, etc.
 *
 * The target should remain in this state until a call to
 * GSoundTargetAudioInClose.
 *
 * Note, if a Target does not require any custom configuration to enable high
 * throughput streaming, simply return GSOUND_STATUS_OK.
 *
 * param[in]: settings  Pointer to audio streaming settings. The content
 *                      of this structure must be fully consumed before this
 *                      function returns. Target must retain any information
 *                      from this parameter to reuse during
 *                      GSoundTargetAudioInClose. Refer to type
 *                      GSoundTargetAudioStreamingSettings for more information.
 */
GSoundStatus GSoundTargetAudioPrepareForStreaming(
    const GSoundTargetAudioStreamingSettings *settings);

/**
 * Initialize Microphone Audio Input path.
 *
 * Audio In should only come from the Microphone.
 * This is used to capture Voice Input which will be
 * used as a Google Assistant Query.
 *
 * The Audio must be SBC encoded.
 * For SBC, we require that the header is removed from each audio frame.
 */

GSoundStatus GSoundTargetAudioInInit(const GSoundAudioInterface *handler);

#ifdef __cplusplus
}
#endif

#endif  // GSOUND_TARGET_AUDIO_H
